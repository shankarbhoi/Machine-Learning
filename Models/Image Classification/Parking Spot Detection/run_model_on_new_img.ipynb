{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This program takes an input image and processes it against the stored CNN model and the co-ordinates of the parking slots and returns an image with the empty slots marked in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os, glob\n",
    "import numpy as np\n",
    "## Imports for making predictions\n",
    "from PIL import Image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import pickle\n",
    "#importing Config file\n",
    "import import_ipynb\n",
    "import Config as c\n",
    "\n",
    "with open(c.pickle_file, 'rb') as handle:\n",
    "    final_spot_dict = pickle.load(handle)\n",
    "\n",
    "def show_images(images, cmap=None):\n",
    "    cols = 2\n",
    "    rows = (len(images)+1)//cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        # use gray scale color map if there is only one channel\n",
    "        cmap = 'gray' if len(image.shape)==2 else cmap\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Image\n",
    "test_images = [plt.imread(path) for path in glob.glob(c.img_path)]\n",
    "show_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trained CNN model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "top_model_weights_path = c.model_file\n",
    "\n",
    "class_dictionary = {}\n",
    "class_dictionary[0] = 'empty'\n",
    "class_dictionary[1] = 'occupied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "model = load_model(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(image):\n",
    "    #Rescale image\n",
    "    img = image/255.\n",
    "\n",
    "    #Convert to a 4D tensor\n",
    "    image = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # make predictions on the preloaded model\n",
    "    class_predicted = model.predict(image)\n",
    "    inID = np.argmax(class_predicted[0])\n",
    "    label = class_dictionary[inID]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_slots=[]\n",
    "def predict_on_image(image, spot_dict = final_spot_dict, make_copy=True, color = [c.slot_color_r, c.slot_color_g, c.slot_color_b], alpha=0.5):\n",
    "    if make_copy:\n",
    "        new_image = np.copy(image)\n",
    "        overlay = np.copy(image)\n",
    "    cnt_empty = 0\n",
    "    all_spots = 0\n",
    "    for spot in spot_dict.keys():\n",
    "        all_spots += 1\n",
    "        (x1, y1, x2, y2) = spot\n",
    "        (x1, y1, x2, y2) = (int(x1), int(y1), int(x2), int(y2))\n",
    "        #crop this image\n",
    "        spot_img = image[y1:y2, x1:x2]\n",
    "        spot_img = cv2.resize(spot_img, (c.test_image_width,c.test_image_height)) \n",
    "        \n",
    "        label = make_prediction(spot_img)\n",
    "        if label == 'empty':\n",
    "            cv2.rectangle(overlay, (int(x1),int(y1)), (int(x2),int(y2)), color, -1)\n",
    "            coordinate=x1,y1,x2,y2\n",
    "            empty_slots.append(coordinate)\n",
    "            cnt_empty += 1\n",
    "            \n",
    "    cv2.addWeighted(overlay, alpha, new_image, 1 - alpha, 0, new_image)\n",
    "            \n",
    "    cv2.putText(new_image, \"Available: %d spots\" %cnt_empty, (c.available_font_width, c.available_font_height),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    0.7, (c.font_r, c.font_g, c.font_b), c.channels)\n",
    "    \n",
    "    cv2.putText(new_image, \"Total: %d spots\" %all_spots, (c.total_font_width, c.total_font_height),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    0.7, (c.font_r, c.font_g, c.font_b), c.channels)\n",
    "    save = False\n",
    "    \n",
    "    if save:\n",
    "        filename = c.filename_with_marker\n",
    "        cv2.imwrite(filename, new_image)\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "\n",
    "predicted_images = list(map(predict_on_image, test_images))\n",
    "show_images(predicted_images)\n",
    "print(empty_slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
