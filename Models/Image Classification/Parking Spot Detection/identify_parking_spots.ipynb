{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This program takes an input image of an parking lot and processes it to return the co-ordinates of the parking slot in a pickle file. The various config values for the image transforms are stored ia config file which is loaded into the program at the start. This program needs to be tuned at the start of the installation for a specific parking lot as a one time setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "cwd = os.getcwd()\n",
    "#importing Config file\n",
    "import import_ipynb\n",
    "import Config as c\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "def show_images(images, cmap=None):\n",
    "    cols = 2\n",
    "    rows = (len(images)+1)//cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 12))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        # use gray scale color map if there is only one channel\n",
    "        cmap = 'gray' if len(image.shape)==2 else cmap\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Image\n",
    "test_images = [plt.imread(path) for path in glob.glob(c.img_path)]\n",
    "show_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Selection and Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image is expected be in RGB color space# image \n",
    "def select_rgb_white_yellow(image): \n",
    "    # white color mask\n",
    "    lower = np.uint8([c.white_lower_r,c.white_lower_g,c.white_lower_b])\n",
    "    upper = np.uint8([c.white_upper_r, c.white_upper_g, c.white_upper_b])\n",
    "    white_mask = cv2.inRange(image, lower, upper)\n",
    "    # yellow color mask\n",
    "    lower = np.uint8([c.yellow_lower_r,c.yellow_lower_g,c.yellow_lower_b])\n",
    "    upper = np.uint8([c.yellow_upper_r,c.yellow_upper_g,c.yellow_upper_b])\n",
    "    yellow_mask = cv2.inRange(image, lower, upper)\n",
    "    # combine the mask\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return masked\n",
    "\n",
    "def convert_gray_scale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "white_yellow_images = list(map(select_rgb_white_yellow, test_images))\n",
    "#show_images(white_yellow_images)\n",
    "\n",
    "gray_images = list(map(convert_gray_scale, white_yellow_images))\n",
    "show_images(gray_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blur, Canny Transform and Hough line transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_edges(image, low_threshold=c.low_threshold, high_threshold=c.high_threshold):\n",
    "    int_img = cv2.GaussianBlur(image, (3,15),0)\n",
    "    #plt.imshow(int_img)\n",
    "    return cv2.Canny(int_img, low_threshold, high_threshold)\n",
    "\n",
    "def hough_lines(image):\n",
    "    \"\"\"\n",
    "    `image` should be the output of a Canny transform.\n",
    "    \n",
    "    Returns hough lines (not the image with lines)\n",
    "    \"\"\"\n",
    "    return cv2.HoughLinesP(image, rho=1, theta=np.pi/c.divisor, threshold=c.threshold_value, minLineLength=c.houghline_minlinelength, maxLineGap=c.houghline_maxlinegap)\n",
    "\n",
    "\n",
    "def draw_lines(image, lines, color=[255, 0, 0], thickness=c.draw_lines_thickness, make_copy=True):\n",
    "    # the lines returned by cv2.HoughLinesP has the shape (-1, 1, 4)\n",
    "    if make_copy:\n",
    "        image = np.copy(image) # don't want to modify the original\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if abs(y2-y1) <=c.lines_y_threshold_rect and abs(x2-x1) >=c.lines_x_threshold1_rect and abs(x2-x1) <= c.lines_x_threshold2_rect:\n",
    "            #if abs(x2-x1) >=25 and abs(x2-x1) <= 50:\n",
    "                cleaned.append((x1,y1,x2,y2))\n",
    "                cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    print(\" No lines detected: \", len(cleaned))\n",
    "    return image\n",
    "\n",
    "#Apply gaussian blur and canny transform \n",
    "edge_images = list(map(lambda image: detect_edges(image), gray_images))\n",
    "#show_images(edge_images)\n",
    "#show_images(edge_images)\n",
    "# Hough line transform\n",
    "list_of_lines = list(map(hough_lines, edge_images))\n",
    "\n",
    "#Draw the lines on the image\n",
    "line_images = []\n",
    "for image, lines in zip(test_images, list_of_lines):\n",
    "    line_images.append(draw_lines(image, lines))\n",
    "    \n",
    "show_images(line_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify rectangular blocks of parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_blocks(image, lines, make_copy=True):\n",
    "    if make_copy:\n",
    "        new_image = np.copy(image)\n",
    "       \n",
    "    #Step 1: Create a clean list of lines\n",
    "    cleaned = []\n",
    "    gap_list = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if abs(y2-y1) <=c.lines_y_threshold and abs(x2-x1) >=c.lines_x_threshold1 and abs(x2-x1) <= c.lines_x_threshold2:\n",
    "                cleaned.append((x1,y1,x2,y2))\n",
    "                gap_list.append((y1))\n",
    "    \n",
    "    #Step 2: Sort cleaned by x1 position\n",
    "    import operator\n",
    "    list1 = sorted(cleaned, key=operator.itemgetter(0, 1))    \n",
    "    #Step 3: Find clusters of x1 close together - clust_dist apart\n",
    "    clusters = {}\n",
    "    dIndex = 0   \n",
    "    clus_dist = c.clust_dist\n",
    "\n",
    "    for i in range(len(list1) - 1):\n",
    "        distance = abs(list1[i+1][0] - list1[i][0])\n",
    "        if distance <= clus_dist:\n",
    "            if not dIndex in clusters.keys(): clusters[dIndex] = []\n",
    "            clusters[dIndex].append(list1[i])\n",
    "            clusters[dIndex].append(list1[i + 1])\n",
    "\n",
    "        else:\n",
    "            dIndex += 1\n",
    "    \n",
    "    #Step 4: Identify coordinates of rectangle around this cluster\n",
    "    rects = {}\n",
    "    i = 0\n",
    "    for key in clusters:\n",
    "        all_list = clusters[key]\n",
    "        cleaned = list(set(all_list))\n",
    "        if len(cleaned) > c.threshold_value:\n",
    "            \n",
    "            cleaned = sorted(cleaned, key=lambda tup: tup[1])\n",
    "            avg_y1 = cleaned[0][1]\n",
    "            avg_y2 = cleaned[-1][1]\n",
    "            avg_x1 = c.max_image_width #put the max width of the image\n",
    "            avg_x2 = 0\n",
    "            for tup in cleaned:\n",
    "                avg_x1 = min(avg_x1, tup[0])\n",
    "                avg_x2 = max(avg_x2, tup[2])\n",
    "            rects[i] = (avg_x1, avg_y1, avg_x2, avg_y2)\n",
    "            i += 1\n",
    "            \n",
    "    print(\"Num Parking Lanes: \", len(rects))\n",
    "    \n",
    "    \n",
    "    #Step 5: Draw the rectangles on the image\n",
    "    buff = 0\n",
    "    for key in rects:\n",
    "        tup_topLeft = (int(rects[key][0] - buff), int(rects[key][1]))\n",
    "        tup_botRight = (int(rects[key][2] + buff), int(rects[key][3]))\n",
    "        cv2.rectangle(new_image, tup_topLeft,tup_botRight,(c.rect_color_r,c.rect_color_g,c.rect_color_b),c.rect_channels)\n",
    "    return new_image, rects\n",
    "\n",
    "# images showing the region of interest only\n",
    "rect_images = []\n",
    "rect_coords = []\n",
    "for image, lines in zip(test_images, list_of_lines):\n",
    "    new_image, rects = identify_blocks(image, lines)\n",
    "    rect_images.append(new_image)\n",
    "    rect_coords.append(rects)\n",
    "    \n",
    "show_images(rect_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify each spot and count num of parking spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step- \n",
    "1. Based on width of each parking line segment into individual spots\n",
    "2. draw a visualization of all parking spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_parking(image, rects, make_copy = True, color=[255, 0, 0], thickness=c.draw_lines_thickness, save = True):\n",
    "    if make_copy:\n",
    "        new_image = np.copy(image)\n",
    "    gap = c.gap\n",
    "    spot_dict = {} # maps each parking ID to its coords\n",
    "    tot_spots = 0\n",
    "    for key in rects:\n",
    "        # Horizontal lines\n",
    "        tup = rects[key]\n",
    "        x1 = int(tup[0])\n",
    "        x2 = int(tup[2])\n",
    "        y1 = int(tup[1])\n",
    "        y2 = int(tup[3])\n",
    "        cv2.rectangle(new_image, (x1, y1),(x2,y2),(0,255,0),2)\n",
    "        num_splits = int(abs(y2-y1)//gap)\n",
    "        tot_spots += num_splits + 1\n",
    "        #print(num_splits)\n",
    "        for i in range(0, num_splits+1):\n",
    "            y = int(y1 + i*gap)\n",
    "            cv2.line(new_image, (x1, y), (x2, y), color, thickness)\n",
    "            \n",
    "        for i in range(0, num_splits+1):\n",
    "            cur_len = len(spot_dict)\n",
    "            y = int(y1 + i*gap)\n",
    "            x = int(x1)\n",
    "            spot_dict[(x1, y, x2, y+gap)] = cur_len +1\n",
    "            \n",
    "    \n",
    "    print(\"total parking spaces: \", tot_spots, cur_len)\n",
    "    if save:\n",
    "        filename = 'test.jpg'\n",
    "        cv2.imwrite(filename, new_image)\n",
    "    return new_image, spot_dict\n",
    "\n",
    "delineated = []\n",
    "spot_pos = []\n",
    "for image, rects in zip(test_images, rect_coords):\n",
    "    new_image, spot_dict = draw_parking(image, rects)\n",
    "    delineated.append(new_image)\n",
    "    spot_pos.append(spot_dict) \n",
    "show_images(delineated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_spot_dict = spot_pos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_spot_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_spots_map(image, spot_dict=final_spot_dict, make_copy = True, color=[255, 0, 0], thickness=c.draw_lines_thickness):\n",
    "    if make_copy:\n",
    "        new_image = np.copy(image)\n",
    "    for spot in spot_dict.keys():\n",
    "        (x1, y1, x2, y2) = spot\n",
    "        cv2.rectangle(new_image, (int(x1),int(y1)), (int(x2),int(y2)), color, thickness)\n",
    "    return new_image\n",
    "\n",
    "marked_spot_images = list(map(assign_spots_map, test_images))\n",
    "show_images(marked_spot_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save spot dictionary as pickle file\n",
    "import pickle\n",
    "with open(c.pickle_file, 'wb') as handle:\n",
    "    pickle.dump(final_spot_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
